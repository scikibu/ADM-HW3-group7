{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import csv, sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the initial csv file and remove unnamed column\n",
    "df = pd.read_csv('C:\\\\Users\\\\Olya\\Documents\\\\Various documents\\\\Masters\\\\La Sapienza\\\\ADM\\\\Homework\\\\Homework 3\\\\airbnb-property-data-from-texas\\\\Airbnb_Texas_Rentals.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one tsv file per each row\n",
    "df = pd.read_csv('C:\\\\Users\\\\Olya\\Documents\\\\Various documents\\\\Masters\\\\La Sapienza\\\\ADM\\\\Homework\\\\Homework 3\\\\airbnb-property-data-from-texas\\\\Airbnb_Texas_Rentals.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "for i in range(df.index.max()+1):\n",
    "        new = open('doc_'+str(i)+'.tsv', 'w')\n",
    "        for j in range(9):\n",
    "               new.write('%s\\t' %df.iloc[i, j])\n",
    "        new.close()\n",
    "        if i > 2: # for the moment just making 4 files\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to remove stop words from specified column from data frame\n",
    "# in our case we'll call it for the title (column 4) and description (column 7)\n",
    "def remove_stopwords(df, n):\n",
    "    #remove stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    df[n] = df[n].apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to remove punctuation from specified column from data frame\n",
    "# in our case we'll call it for the title (column 4) and description (column 7)\n",
    "def remove_punctuation(df, n):\n",
    "    df[n] = df[n].str.replace('[^\\w\\s]','') \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to put everything to lowercase from specified column from data frame\n",
    "# in our case we'll call it for the title (column 4) and description (column 7)\n",
    "def to_lowercase(df, n):\n",
    "    df[n] = df[n].apply(lambda x: \" \".join(x.lower() for x in x.split())) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to do stemming from specified column from data frame\n",
    "# in our case we'll call it for the title (column 4) and description (column 7)\n",
    "def stemming(df, n):\n",
    "    st = PorterStemmer()\n",
    "    df[n] = df[n].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which makes unique words from max 2 given columns from data frame\n",
    "# second argument can be omitted\n",
    "# !!!!! what shell we do with numbers? keep them as a word or remove them?\n",
    "\n",
    "def unique_words(df, n, m):\n",
    "    a=set(\" \".join(df[n]).split(\" \"))\n",
    "    if m == None:\n",
    "          b=set() # empty set for the second argument\n",
    "    else:\n",
    "        b=set(\" \".join(df[m]).split(\" \"))\n",
    "    # return unique words\n",
    "    return a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_idx(inverted_idx, w, i):\n",
    "    for w in doc_unique_words:\n",
    "        inverted_idx[w].append(i)\n",
    "    return inverted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of all unique words appearing in documents\n",
    "vocab={}\n",
    "# word index of all unique words appearing in documents\n",
    "word_idx=defaultdict(list)\n",
    "\n",
    "# inverted index\n",
    "inverted_idx={}\n",
    "\n",
    "for i in range(0,3): #len(df.index)+1\n",
    "    #temoporaly create a dataframe from our tsv files\n",
    "    tsv = pd.read_csv('doc_{}.tsv'.format(i), sep='\\t', encoding = 'ISO-8859-1', header = None)\n",
    "    \n",
    "    # replacing \\n with the space\n",
    "    tsv = tsv.replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\\\n',  ' ', regex=True)\n",
    "    \n",
    "    # replacing / with the space\n",
    "    tsv = tsv.replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'/',  ' ', regex=True)\n",
    "    \n",
    "    # Data pre-processing\n",
    "    tsv=remove_stopwords(tsv, 4) # remove stop words in title\n",
    "    tsv=remove_stopwords(tsv, 7) # remove stop words in description\n",
    "    tsv=remove_punctuation(tsv, 4) # remove punctuation in title\n",
    "    tsv=remove_punctuation(tsv, 7) # remove punctuation in description\n",
    "    tsv=to_lowercase(tsv, 4) # put title into lower case\n",
    "    tsv=to_lowercase(tsv, 7) # put title into lower case\n",
    "    tsv=stemming(tsv, 4) # make stemming in title\n",
    "    tsv=stemming(tsv, 7) # make stemming in description\n",
    "    \n",
    "    # make a set of unique words from description and title of a document\n",
    "    doc_unique_words=unique_words(tsv,4,7)\n",
    "    \n",
    "    # update current vocabulary with the new words found in a document\n",
    "    for w in doc_unique_words:\n",
    "        if w in vocab.values(): # if word is already in general vocabulary skip it\n",
    "            continue\n",
    "        else:\n",
    "            if any(vocab)==False: #if vocabulary is empty then define initial integer key for the first word\n",
    "                v_idx=10000\n",
    "                vocab.update( { v_idx: w} ) # add a word to the vocabulary\n",
    "            else: # if vocabulary already has words, take the first available key (max(key)+1) for the next word\n",
    "                v_idx=max(list(vocab.keys()))+1\n",
    "                vocab.update( { v_idx: w} ) # add a word to the vocabulary\n",
    "                \n",
    "    # create index dictionary which for each word will have list of document numbers which contain that word\n",
    "    for w in doc_unique_words:\n",
    "        word_idx[w].append(i)\n",
    "word_idx=dict(word_idx)\n",
    "\n",
    "# Inverted index for all the words - dictionary with word_id as a key and list of the id of the documents that contain the word\n",
    "inverted_idx=dict((key,word_idx[value]) for (key, value) in vocab.items())\n",
    "\n",
    "with open('inverted_index.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, inverted_idx.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(inverted_idx)\n",
    "\n",
    "with open('vocabulary.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, vocab.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10000: '2',\n",
       " 10001: 'drop',\n",
       " 10002: 'bedroom',\n",
       " 10003: 'bed',\n",
       " 10004: 'trip',\n",
       " 10005: 'airport',\n",
       " 10006: 'iah',\n",
       " 10007: '10min',\n",
       " 10008: '10',\n",
       " 10009: 'avail',\n",
       " 10010: 'addit',\n",
       " 10011: 'queen',\n",
       " 10012: 'room',\n",
       " 10013: 'bathroom',\n",
       " 10014: 'pickup',\n",
       " 10015: 'privat',\n",
       " 10016: 'sofa',\n",
       " 10017: 'guest',\n",
       " 10018: 'welcom',\n",
       " 10019: 'detach',\n",
       " 10020: 'floor',\n",
       " 10021: 'stay',\n",
       " 10022: 'second',\n",
       " 10023: 'anoth',\n",
       " 10024: 'open',\n",
       " 10025: 'remodel',\n",
       " 10026: '281',\n",
       " 10027: 'amaz',\n",
       " 10028: 'prestigi',\n",
       " 10029: 'plan',\n",
       " 10030: 'nw',\n",
       " 10031: 'european',\n",
       " 10032: '3',\n",
       " 10033: 'decor',\n",
       " 10034: 'home',\n",
       " 10035: 'conveni',\n",
       " 10036: 'driveway',\n",
       " 10037: 'downtown',\n",
       " 10038: 'gardentv',\n",
       " 10039: 'full',\n",
       " 10040: 'car',\n",
       " 10041: 'street',\n",
       " 10042: 'season',\n",
       " 10043: '4',\n",
       " 10044: 'park',\n",
       " 10045: 'hardwood',\n",
       " 10046: 'fulli',\n",
       " 10047: 'inspir',\n",
       " 10048: 'design',\n",
       " 10049: 'sleep',\n",
       " 10050: 'locat',\n",
       " 10051: 'line',\n",
       " 10052: 'kitchen',\n",
       " 10053: 'quiet',\n",
       " 10054: 'hous',\n",
       " 10055: 'upscal',\n",
       " 10056: 'tree',\n",
       " 10057: '410',\n",
       " 10058: 'neighborhood',\n",
       " 10059: 'featur',\n",
       " 10060: 'beauti',\n",
       " 10061: 'origin',\n",
       " 10062: 'close',\n",
       " 10063: 'loop',\n",
       " 10064: 'area',\n",
       " 10065: 'alamo',\n",
       " 10066: 'height',\n",
       " 10067: 'uniqu',\n",
       " 10068: 'stylish',\n",
       " 10069: 'independ',\n",
       " 10070: 'top',\n",
       " 10071: 'maintain',\n",
       " 10072: 'visitor',\n",
       " 10073: 'near',\n",
       " 10074: 'island',\n",
       " 10075: 'citi',\n",
       " 10076: 'jacinto',\n",
       " 10077: 'san',\n",
       " 10078: 'river',\n",
       " 10079: 'a',\n",
       " 10080: 'temporari',\n",
       " 10081: 'extra',\n",
       " 10082: 'well'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
